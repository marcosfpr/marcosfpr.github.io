<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Papers</title>
    <link rel="stylesheet" href="../style.css">
    <script defer src="../theme.js"></script>

    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['\\(', '\\)']],
                displayMath: [['\\[', '\\]']],
                processEscapes: true
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>

<body>
    <header>
        <h1>marcosfpr</h1>
        <nav>
            <a href="../index.html">Home</a> |
            <a href="index.html">Wiki</a> |
            <button id="theme-toggle" aria-label="Toggle light/dark">Light/Dark</button>
        </nav>
    </header>

    <main>
        
<div id="Papers List"><h1 id="Papers List" class="header"><a href="#Papers List">Papers List</a></h1></div>

<p>
This page contains a list of academic papers and articles that I have found useful or interesting.
I will update this list over time as I discover more papers (or as I find time to add them here).
</p>

<div id="Papers List-Miscellaneous"><h2 id="Miscellaneous" class="header"><a href="#Papers List-Miscellaneous">Miscellaneous</a></h2></div>

<ul>
<li>
<a href="https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf">Reflections on Trusting Trust</a> - Ken Thompson.

<li>
<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/acrobat-17.pdf">Hints for Computer System Design</a> - Butler Lampson.

<li>
<a href="https://curtclifton.net/papers/MoseleyMarks06a.pdf">Out of the Tar Pit</a> - Ben Moseley et al.

</ul>
<div id="Papers List-Cybersecurity"><h2 id="Cybersecurity" class="header"><a href="#Papers List-Cybersecurity">Cybersecurity</a></h2></div>

<div id="Papers List-Cybersecurity-Cryptography"><h3 id="Cryptography" class="header"><a href="#Papers List-Cybersecurity-Cryptography">Cryptography</a></h3></div>
<div id="Papers List-Cybersecurity-Cryptography-Homomorphic Encryption"><h4 id="Homomorphic Encryption" class="header"><a href="#Papers List-Cybersecurity-Cryptography-Homomorphic Encryption">Homomorphic Encryption</a></h4></div>
<ul>
<li>
<a href="https://eprint.iacr.org/2017/715.pdf?trk=public_post_comment-text">Privacy-Preserving Deep Learning via Additively Homomorphic Encryption</a> - Le Trieu Phong et al.

</ul>
<div id="Papers List-Cybersecurity-Adversarial Machine Learning"><h3 id="Adversarial Machine Learning" class="header"><a href="#Papers List-Cybersecurity-Adversarial Machine Learning">Adversarial Machine Learning</a></h3></div>

<ul>
<li>
<a href="https://arxiv.org/pdf/1607.00133">Deep Learning with Differential Privacy</a> -	Martín Abadi et al.

<li>
<a href="https://pmpml.github.io/PMPML16/papers/PMPML16_paper_8.pdf">Practical Secure Aggregation for Federated Learning on User-Held Data</a> - Keith Bonawitz et al.

<li>
<a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/60a6c4002cc7b29142def8871531281a-Paper.pdf">Deep Leakage from Gradients</a> - Ligeng Zhu et al.

<li>
<a href="https://www.comp.nus.edu.sg/~reza/files/Shokri-SP2019.pdf">Comprehensive Privacy Analysis of Deep Learning</a> -	Milad Nasr et al.

<li>
<a href="https://ozankoyluoglu.github.io/pdfs/ICML20_CCS20_FastSecAgg.pdf">FastSecAgg: Scalable Secure Aggregation for Privacy-Preserving Federated Learning</a> - Swanand Kadhe et al.

<li>
<a href="https://arxiv.org/pdf/2001.02610">iDLG: Improved Deep Leakage from Gradients</a> - Bo Zhao et al.

<li>
<a href="https://papers.neurips.cc/paper_files/paper/2020/file/c4ede56bbd98819ae6112b20ac6bf145-Paper.pdf">Inverting Gradients - How easy is it to break privacy in federated learning?</a> - Jonas Geiping et al.

<li>
<a href="https://openreview.net/pdf/943e8621d1ff1fb8b9daa8cc68876c327966099c.pdf">R-GAP: Recursive Gradient Attack on Privacy</a> -	Junyi Zhu et al.

<li>
<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_See_Through_Gradients_Image_Batch_Recovery_via_GradInversion_CVPR_2021_paper.pdf">See through Gradients: Image Batch Recovery via GradInversion</a> -	Hongxu Yin et al.

<li>
<a href="https://fl-icml.github.io/2021/papers/FL-ICML21_paper_75.pdf">Gradient Inversion with Generative Image Prior</a> -	Jinwoo Jeon et al.

<li>
<a href="https://papers.neurips.cc/paper/2021/file/08040837089cdf46631a10aca5258e16-Paper.pdf">CAFE: Catastrophic Data Leakage in Vertical Federated Learning</a> -	Xiao Jin et al.

<li>
<a href="https://aclanthology.org/2021.findings-emnlp.305.pdf">TAG: Gradient Attack on Transformer-based Language Models</a> -	Jieren Deng et al.

<li>
<a href="https://arxiv.org/pdf/2202.08827">LAMP: Extracting Text from Gradients with Language Model Priors</a> - Mislav Balunović et al.

<li>
<a href="https://openreview.net/pdf?id=r0BrY4BiEXO">Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models</a> -	Liam Fowl et al.

<li>
<a href="https://openreview.net/pdf/f001474d4a74672028ea06af6f68b4e7c71bca47.pdf">Robbing the Fed: Directly Obtaining Private Data in Federated Learning with Modified Models</a> -	Liam Fowl et al.

<li>
<a href="https://proceedings.mlr.press/v162/wen22a/wen22a.pdf">Fishing for User Data in Large-Batch Federated Learning via Gradient Magnification</a> -	Yuxin Wen et al.

<li>
<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_APRIL_Finding_the_Achilles_Heel_on_Privacy_for_Vision_Transformers_CVPR_2022_paper.pdf">APRIL: Finding the Achilles' Heel on Privacy for Vision Transformers</a> -	Lu et al.

<li>
<a href="https://arxiv.org/pdf/2111.07380">Eluding Secure Aggregation in Federated Learning via Model Inconsistency</a> -	Pasquini et al.

<li>
<a href="https://www.researchgate.net/publication/357853477_A_Survey_of_Image_Gradient_Inversion_Against_Federated_Learning">A Survey of Image Gradient Inversion Against Federated Learning</a> -	Zhaohua Li et al.

<li>
<a href="https://www.researchgate.net/publication/355391514_Towards_General_Deep_Leakage_in_Federated_Learning">Towards General Deep Leakage in Federated Learning</a> -	Jiahui Geng et al.

<li>
<a href="https://arxiv.org/pdf/2206.07284">A Survey on Gradient Inversion: Attacks, Defenses and Future Directions</a> -	Rui Zhang et al.

<li>
<a href="https://arxiv.org/pdf/2112.13178">Gradient Leakage Attack Resilient Deep Learning</a> -	Wenqi We et al.

<li>
<a href="https://arxiv.org/pdf/2110.03816">PRECODE - A Generic Model Extension to Prevent Deep Gradient Leakage</a> -	Daniel Schelig et al.

<li>
<a href="https://arxiv.org/pdf/2109.14236">LightSecAgg: Rethinking Secure Aggregation in Federated Learning</a> -	Jinhyun So et al.

<li>
<a href="https://arxiv.org/pdf/2201.08135">Survey on Federated Learning Threats: concepts, taxonomy on attacks and defences, experimental study and challenges</a> -	Nuria Rodríguez-Barroso et al.

<li>
<a href="https://arxiv.org/pdf/2112.02918">When the Curious Abandon Honesty: Federated Learning Is Not Private</a> -	Boenisch et al.

<li>
<a href="https://arxiv.org/pdf/2405.15586">DAGER: Exact Gradient Inversion for Large Language Models</a> - Ivo Petrov et al.

<li>
<a href="https://arxiv.org/pdf/2402.04013">Privacy Leakage on DNNs: A Survey of Model Inversion Attacks and Defenses</a> -Hao Fang et al.

</ul>

    </main>

    <footer>
        &copy; 2024 marcosfpr
    </footer>
</body>

</html>
